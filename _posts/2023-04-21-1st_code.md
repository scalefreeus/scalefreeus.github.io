---
layout:     post
title:      "test"
subtitle:   "test"
date:       2023-04-21 15:00:00
author:     "Scalefreeus"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - Algorithm
    - CPP
---

## Dacon 9회 펀다 상점매출예측 모델링 경진대회
## DB분석가(이건희, 최종승)

## 1. 라이브러리 및 데이터
## Library & Data

- 시계열 모델링을 간편하게 하기 위해 R의 forecast, forecastHybrid 패키지를 사용합니다.
- R패키지를 사용하기 위해 rpy2 파이썬 패키지를 설치합니다.
- rpy2는 pip으로 설치하면 오류가 발생하므로 Anaconda Prompt창에서 conda install -c r rpy2 명령어로 설치하시기 바랍니다.
- Numpy: 1.18.2          
- Pandas: 0.25.1         
- pmdarima: 1.5.3        
- seaborn: 0.9.0         
- statsmodel: 0.11.1     
- matplotlib: 3.1.1      
- rpy2: 2.9.4            


```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
import pmdarima as pm
import pmdarima
import statsmodels
import rpy2
import rpy2.robjects as robjects  ##R 함수를 쓰기위함
from tqdm import tqdm
from rpy2.robjects import pandas2ri ##pandas를 R 데이터로 형식으로 변환하기 위함
from rpy2.robjects.packages import importr #R 패키지를 import
from pmdarima.arima.stationarity import ADFTest #단위근검정 ADF_TEST
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf #AR값을 정하기위한 acf,pcaf
import warnings

warnings.filterwarnings("ignore")

print('Numpy: %s'%(np.__version__))
print('Pandas: %s'%(pd.__version__))
print('pmdarima: %s'%(pmdarima.__version__))
print('seaborn: %s'%(sns.__version__))
print('statsmodel: %s'%(statsmodels.__version__))
print('matplotlib: %s'%(matplotlib.__version__))
print('rpy2: %s'%(rpy2.__version__))
```

    Numpy: 1.18.2
    Pandas: 0.25.1
    pmdarima: 1.5.3
    seaborn: 0.10.1
    statsmodel: 0.11.1
    matplotlib: 3.2.2
    rpy2: 2.9.4
    


```python
utils = importr('utils') ##utils 패키지를 import
utils.install_packages('forecast') ##R의 forecast패키지를 설치한다.
utils.install_packages('forecastHybrid') #R의 forecastHybrid패키지 설치
```




    rpy2.rinterface.NULL




```python
pandas2ri.activate() ##모델링시 판다스를 R 데이터로 변환하기위해 activate 시켜야함
train = pd.read_csv('C:/data/funda_train.csv')
submission = pd.read_csv('C:/data/submission.csv')
```


```python
train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>store_id</th>
      <th>card_id</th>
      <th>card_company</th>
      <th>transacted_date</th>
      <th>transacted_time</th>
      <th>installment_term</th>
      <th>region</th>
      <th>type_of_business</th>
      <th>amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>b</td>
      <td>2016-06-01</td>
      <td>13:13</td>
      <td>0</td>
      <td>NaN</td>
      <td>기타 미용업</td>
      <td>1857.142857</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>h</td>
      <td>2016-06-01</td>
      <td>18:12</td>
      <td>0</td>
      <td>NaN</td>
      <td>기타 미용업</td>
      <td>857.142857</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>c</td>
      <td>2016-06-01</td>
      <td>18:52</td>
      <td>0</td>
      <td>NaN</td>
      <td>기타 미용업</td>
      <td>2000.000000</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0</td>
      <td>3</td>
      <td>a</td>
      <td>2016-06-01</td>
      <td>20:22</td>
      <td>0</td>
      <td>NaN</td>
      <td>기타 미용업</td>
      <td>7857.142857</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0</td>
      <td>4</td>
      <td>c</td>
      <td>2016-06-02</td>
      <td>11:06</td>
      <td>0</td>
      <td>NaN</td>
      <td>기타 미용업</td>
      <td>2000.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
plt.figure(figsize=(13, 4))
plt.bar(train.columns, train.isnull().sum())
plt.xticks(rotation=45)
```




    ([0, 1, 2, 3, 4, 5, 6, 7, 8], <a list of 9 Text major ticklabel objects>)




    
![png](/img/1st_code_files/1st_code_7_1.png)
    



```python
train=train.drop(['region','type_of_business'],axis=1)
train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>store_id</th>
      <th>card_id</th>
      <th>card_company</th>
      <th>transacted_date</th>
      <th>transacted_time</th>
      <th>installment_term</th>
      <th>amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>b</td>
      <td>2016-06-01</td>
      <td>13:13</td>
      <td>0</td>
      <td>1857.142857</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>h</td>
      <td>2016-06-01</td>
      <td>18:12</td>
      <td>0</td>
      <td>857.142857</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>c</td>
      <td>2016-06-01</td>
      <td>18:52</td>
      <td>0</td>
      <td>2000.000000</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0</td>
      <td>3</td>
      <td>a</td>
      <td>2016-06-01</td>
      <td>20:22</td>
      <td>0</td>
      <td>7857.142857</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0</td>
      <td>4</td>
      <td>c</td>
      <td>2016-06-02</td>
      <td>11:06</td>
      <td>0</td>
      <td>2000.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
train[train['amount']<0]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>store_id</th>
      <th>card_id</th>
      <th>card_company</th>
      <th>transacted_date</th>
      <th>transacted_time</th>
      <th>installment_term</th>
      <th>amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>41</td>
      <td>0</td>
      <td>40</td>
      <td>a</td>
      <td>2016-06-10</td>
      <td>17:26</td>
      <td>2</td>
      <td>-8571.428571</td>
    </tr>
    <tr>
      <td>347</td>
      <td>0</td>
      <td>285</td>
      <td>a</td>
      <td>2016-08-04</td>
      <td>17:52</td>
      <td>0</td>
      <td>-1857.142857</td>
    </tr>
    <tr>
      <td>731</td>
      <td>0</td>
      <td>473</td>
      <td>g</td>
      <td>2016-10-17</td>
      <td>10:32</td>
      <td>0</td>
      <td>-2000.000000</td>
    </tr>
    <tr>
      <td>831</td>
      <td>0</td>
      <td>230</td>
      <td>b</td>
      <td>2016-11-03</td>
      <td>15:36</td>
      <td>0</td>
      <td>-85.714286</td>
    </tr>
    <tr>
      <td>944</td>
      <td>0</td>
      <td>138</td>
      <td>a</td>
      <td>2016-11-28</td>
      <td>13:21</td>
      <td>0</td>
      <td>-57.142857</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>6556242</td>
      <td>2136</td>
      <td>4663626</td>
      <td>b</td>
      <td>2019-02-01</td>
      <td>21:19</td>
      <td>0</td>
      <td>-13428.571429</td>
    </tr>
    <tr>
      <td>6556448</td>
      <td>2136</td>
      <td>4663760</td>
      <td>d</td>
      <td>2019-02-15</td>
      <td>00:46</td>
      <td>0</td>
      <td>-6928.571429</td>
    </tr>
    <tr>
      <td>6556485</td>
      <td>2136</td>
      <td>4663779</td>
      <td>b</td>
      <td>2019-02-18</td>
      <td>02:45</td>
      <td>0</td>
      <td>-5571.428571</td>
    </tr>
    <tr>
      <td>6556489</td>
      <td>2136</td>
      <td>4663780</td>
      <td>d</td>
      <td>2019-02-18</td>
      <td>21:43</td>
      <td>0</td>
      <td>-8571.428571</td>
    </tr>
    <tr>
      <td>6556608</td>
      <td>2136</td>
      <td>4663855</td>
      <td>d</td>
      <td>2019-02-28</td>
      <td>23:20</td>
      <td>0</td>
      <td>-4500.000000</td>
    </tr>
  </tbody>
</table>
<p>73100 rows × 7 columns</p>
</div>



## 2. 데이터 전처리
## Data Cleansing & Pre-Processing

* 매출액에 음수 값이 보이고, 환불은 금액으로 예상됨
* 환불은 log 정규화를 했을때 무한대가 나오기 때문에 제거 하기로 결정
* 환불발생 이전 데이터 중 카드아이디가 같고 환불액의 절대값이 같은 후보 리스트를 찾음
* 환불 후보리스트 중 가장 최근시간(max)을 제거
* 시계열 모델링을 위해 month 단위로 resampling 진행
* 상점 매출이 발생하지 월은 log 정규화시 0이 아닌 최솟값으로 대치하기 위해 2로 대치(log1=0 ,log2=0.693)
* resampling시 영업 시작전 데이터는 제거하고 시작일 부터 데이터를 유지시킴


상점 매출에 **음수 값이** 존재하는 것이 확인 되었습니다. 환불금액으로 예상됩니다.


```python
plt.figure(figsize=(8, 4))
sns.boxplot(train['amount'])
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1a7a97396c8>




    
![png](1st_code_files/1st_code_13_1.png)
    



```python
train[train['amount']<0].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>store_id</th>
      <th>card_id</th>
      <th>card_company</th>
      <th>transacted_date</th>
      <th>transacted_time</th>
      <th>installment_term</th>
      <th>amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>41</td>
      <td>0</td>
      <td>40</td>
      <td>a</td>
      <td>2016-06-10</td>
      <td>17:26</td>
      <td>2</td>
      <td>-8571.428571</td>
    </tr>
    <tr>
      <td>347</td>
      <td>0</td>
      <td>285</td>
      <td>a</td>
      <td>2016-08-04</td>
      <td>17:52</td>
      <td>0</td>
      <td>-1857.142857</td>
    </tr>
    <tr>
      <td>731</td>
      <td>0</td>
      <td>473</td>
      <td>g</td>
      <td>2016-10-17</td>
      <td>10:32</td>
      <td>0</td>
      <td>-2000.000000</td>
    </tr>
    <tr>
      <td>831</td>
      <td>0</td>
      <td>230</td>
      <td>b</td>
      <td>2016-11-03</td>
      <td>15:36</td>
      <td>0</td>
      <td>-85.714286</td>
    </tr>
    <tr>
      <td>944</td>
      <td>0</td>
      <td>138</td>
      <td>a</td>
      <td>2016-11-28</td>
      <td>13:21</td>
      <td>0</td>
      <td>-57.142857</td>
    </tr>
  </tbody>
</table>
</div>




```python
train['datetime'] = pd.to_datetime(train.transacted_date + " " + 
                                train.transacted_time, format='%Y-%m-%d %H:%M:%S')
```


```python
##환볼 노이즈를 제거 하는 함수
def refund_remove(df):
    refund=df[df['amount']<0]
    non_refund=df[df['amount']>0]
    remove_data=pd.DataFrame()
    
    for i in tqdm(df.store_id.unique()):
        divided_data=non_refund[non_refund['store_id']==i] ##non_refund 스토어 데이터를 스토어별로 나눔
        divided_data2=refund[refund['store_id']==i] ##refund 스토어 데이터를 나눔 스토어별로 나눔
        
        for neg in divided_data2.to_records()[:]: ##환불데이터를 차례대로 검사
            refund_store=neg['store_id']
            refund_id=neg['card_id'] ## 환불 카드 아이디
            refund_datetime=neg['datetime'] ## 환불 시간
            refund_amount=abs(neg['amount']) ## 환불액 절대값을 씌움
                
            ##환불시간 이전의 데이터중 카드이이디와 환불액이 같은 후보 리스트를 뽑는다.
            refund_pay_list=divided_data[divided_data['datetime']<=refund_datetime]
            refund_pay_list=refund_pay_list[refund_pay_list['card_id']==refund_id]
            refund_pay_list=refund_pay_list[refund_pay_list['amount']==refund_amount]
                
                
            #후보리스트가 있으면,카드아이디, 환불액이 같으면서 가장 최근시간을 제거
            if(len(refund_pay_list)!=0):
                refund_datetime=max(refund_pay_list['datetime']) ##가장 최근 시간을 구한다
                remove=divided_data[divided_data['datetime']==refund_datetime] ##가장 최근시간
                remove=remove[remove['card_id']==refund_id] ##환불 카드 아이디
                remove=remove[remove['amount']==refund_amount] ##환불액
                divided_data=divided_data.drop(index=remove.index) #인덱스를 통해 제거
                    
        ##제거한데이터를 데이터프레임에 추가한다.
        remove_data=pd.concat([remove_data,divided_data],axis=0)
    
    return remove_data

##월별로 다운 샘플링해주는 함수
def month_resampling(df):
    new_data=pd.DataFrame() 
    df['year_month']=df['transacted_date'].str.slice(stop=7)
    year_month=df['year_month'].drop_duplicates()
    
    downsampling_data=df.groupby(['store_id', 'year_month']).amount.sum()
    downsampling_data=pd.DataFrame(downsampling_data)
    downsampling_data=downsampling_data.reset_index(drop=False,inplace=False)
    
    for i in tqdm(df.store_id.unique()):
        store=downsampling_data[downsampling_data['store_id']==i]
        start_time=min(store['year_month'])
        store=store.merge(year_month,how='outer')
        store=store.sort_values(by=['year_month'], axis=0, ascending=True) ##데이터를 시간순으로 정렬
        
        store['amount']=store['amount'].fillna(2)   #매출이 발생하지 않는 월은 2로 채움
        store['store_id']=store['store_id'].fillna(i) #store_id 결측치 채운다.
        store=store[store['year_month']>=start_time]  #매출 시작일 이후만 뽑는다.
        
        new_data=pd.concat([new_data,store],axis=0)
        
    return new_data

##상점 매출 시계열 그래프
def store_plot(data,start_id,end_id):
    plt.figure(figsize=(15, 6))
    for i in data['store_id'].unique()[start_id:end_id]:
        plt.plot(data[data['store_id']== i].index, data[data['store_id'] == i].amount, label='store_{}'.format(i))
    plt.legend()   

##상점 매출 분포
def store_displot(data,start_id,end_id):
    plt.figure(figsize=(15, 6))
    for i in data.store_id.unique()[start_id:end_id]:
        sns.distplot(data[data.store_id == i].amount)
    plt.grid()
    plt.show()
    
##ARIMA 모형의 차분 여부를 결정하기 위한 단위근 검정
def adf_test(y):
    adf_test = ADFTest(alpha=0.05)
    p_val, should_diff = adf_test.should_diff(y)
    return p_val

##Series 데이터로 변환 함수
def time_series(df,i):
    store=df[df['store_id']==i]
    index=pd.date_range(min(store['year_month']),'2019-03',freq='BM') ##영업 시작일부터 2019년 2월까지 데이터가 존제
    ts=pd.Series(store['amount'].values,index=index)
    return ts

##acf. pacf 그래프
def acf_pacf_plot(data=None,store_id=None):
    ts=time_series(data,store_id)
    fig = plt.figure(figsize=(12,8))
    ax1 = fig.add_subplot(211)
    plot_acf(ts,lags=20,ax=ax1)
    ax2 = fig.add_subplot(212)
    plot_pacf(ts, lags=20, ax=ax2)

##매출 변동계수를 구하는 함수
def coefficient_variation(df,i):
    cv_data=df.groupby(['store_id']).amount.std()/df.groupby(['store_id']).amount.mean()
    cv=cv_data[i]
    return cv
```


```python
train_remove=refund_remove(train)
```

    100%|██████████████████████████████████████████████████████████████████████████████| 1967/1967 [12:57<00:00,  2.53it/s]
    

환불금액인 **음수값**이 제거 되었었습니다.


```python
plt.figure(figsize=(8, 4))
sns.boxplot(train_remove['amount'])
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1a7a9649ec8>




    
![png](1st_code_files/1st_code_19_1.png)
    



```python
train_remove.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>store_id</th>
      <th>card_id</th>
      <th>card_company</th>
      <th>transacted_date</th>
      <th>transacted_time</th>
      <th>installment_term</th>
      <th>amount</th>
      <th>datetime</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>b</td>
      <td>2016-06-01</td>
      <td>13:13</td>
      <td>0</td>
      <td>1857.142857</td>
      <td>2016-06-01 13:13:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>h</td>
      <td>2016-06-01</td>
      <td>18:12</td>
      <td>0</td>
      <td>857.142857</td>
      <td>2016-06-01 18:12:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>c</td>
      <td>2016-06-01</td>
      <td>18:52</td>
      <td>0</td>
      <td>2000.000000</td>
      <td>2016-06-01 18:52:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0</td>
      <td>3</td>
      <td>a</td>
      <td>2016-06-01</td>
      <td>20:22</td>
      <td>0</td>
      <td>7857.142857</td>
      <td>2016-06-01 20:22:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0</td>
      <td>4</td>
      <td>c</td>
      <td>2016-06-02</td>
      <td>11:06</td>
      <td>0</td>
      <td>2000.000000</td>
      <td>2016-06-02 11:06:00</td>
    </tr>
  </tbody>
</table>
</div>




```python
store_count=len(train_remove.store_id.unique())
len(train_remove[train_remove['datetime']>="2018-12-01"])//store_count
```




    285




```python
##월별로 데이터 다운샘플링 시행 
resampling_data=month_resampling(train_remove)
resampling_data['store_id']=resampling_data['store_id'].astype(int)
pd.set_option('display.float_format', '{:.2f}'.format)
resampling_data
```

    100%|█████████████████████████████████████████████████████████████████████████████| 1967/1967 [00:11<00:00, 177.44it/s]
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>store_id</th>
      <th>year_month</th>
      <th>amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>2016-06</td>
      <td>747000.00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>2016-07</td>
      <td>1005000.00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0</td>
      <td>2016-08</td>
      <td>869714.29</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0</td>
      <td>2016-09</td>
      <td>897857.14</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0</td>
      <td>2016-10</td>
      <td>835428.57</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>17</td>
      <td>2136</td>
      <td>2018-10</td>
      <td>2012214.29</td>
    </tr>
    <tr>
      <td>18</td>
      <td>2136</td>
      <td>2018-11</td>
      <td>2127642.86</td>
    </tr>
    <tr>
      <td>19</td>
      <td>2136</td>
      <td>2018-12</td>
      <td>2427428.57</td>
    </tr>
    <tr>
      <td>20</td>
      <td>2136</td>
      <td>2019-01</td>
      <td>1867785.71</td>
    </tr>
    <tr>
      <td>21</td>
      <td>2136</td>
      <td>2019-02</td>
      <td>2227428.57</td>
    </tr>
  </tbody>
</table>
<p>60982 rows × 3 columns</p>
</div>




```python
col=['store_id','datetime','amount']
train_remove.loc[:,col]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>store_id</th>
      <th>datetime</th>
      <th>amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>2016-06-01 13:13:00</td>
      <td>1857.14</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>2016-06-01 18:12:00</td>
      <td>857.14</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0</td>
      <td>2016-06-01 18:52:00</td>
      <td>2000.00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0</td>
      <td>2016-06-01 20:22:00</td>
      <td>7857.14</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0</td>
      <td>2016-06-02 11:06:00</td>
      <td>2000.00</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>6556606</td>
      <td>2136</td>
      <td>2019-02-28 23:03:00</td>
      <td>3928.57</td>
    </tr>
    <tr>
      <td>6556609</td>
      <td>2136</td>
      <td>2019-02-28 23:24:00</td>
      <td>4142.86</td>
    </tr>
    <tr>
      <td>6556610</td>
      <td>2136</td>
      <td>2019-02-28 23:24:00</td>
      <td>4500.00</td>
    </tr>
    <tr>
      <td>6556611</td>
      <td>2136</td>
      <td>2019-02-28 23:27:00</td>
      <td>571.43</td>
    </tr>
    <tr>
      <td>6556612</td>
      <td>2136</td>
      <td>2019-02-28 23:54:00</td>
      <td>5857.14</td>
    </tr>
  </tbody>
</table>
<p>6406073 rows × 3 columns</p>
</div>




```python
print(type(resampling_data))
```

    <class 'pandas.core.frame.DataFrame'>
    


```python
store_1=time_series(resampling_data,1)
print(type(store_1))
```

    <class 'pandas.core.series.Series'>
    


```python
store_0=time_series(resampling_data,0)
store_0
```




    2016-06-30    747000.00
    2016-07-29   1005000.00
    2016-08-31    869714.29
    2016-09-30    897857.14
    2016-10-31    835428.57
    2016-11-30    697000.00
    2016-12-30    761857.14
    2017-01-31    585642.86
    2017-02-28    794000.00
    2017-03-31    720257.14
    2017-04-28    685285.71
    2017-05-31    744428.57
    2017-06-30    682000.00
    2017-07-31    728285.71
    2017-08-31    749000.00
    2017-09-29    840857.14
    2017-10-31    600571.43
    2017-11-30    630857.14
    2017-12-29    812714.29
    2018-01-31    643142.86
    2018-02-28    685285.71
    2018-03-30    848428.57
    2018-04-30    636142.86
    2018-05-31    686428.57
    2018-06-29    707285.71
    2018-07-31    758714.29
    2018-08-31    679857.14
    2018-09-28    651857.14
    2018-10-31    739000.00
    2018-11-30    676000.00
    2018-12-31    874571.43
    2019-01-31    682857.14
    2019-02-28    515285.71
    Freq: BM, dtype: float64




```python
store_2=time_series(resampling_data,2)
store_2.plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1a7f5170c48>




    
![png](1st_code_files/1st_code_27_1.png)
    



```python
sns.boxplot(store_1)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1a7f522ee48>




    
![png](1st_code_files/1st_code_28_1.png)
    


## 3. 탐색적 자료분석
## Exploratory Data Analysis

* 상점마다 매출 특성과 분포가 다름
* 각 상점 매출액 ADF-Test를 boxplot 한 결과 0.05이상으로 차분이 필요해 보임
* acf, pcaf 그래프를 보면 대부분의 상점의 적정 ar값이 2이하로 보임
* auto_arima 파라미터 튜닝시 max.p 값을 2로 고정, d값은 ndiffs함수로 구함

각 상점별 **매출 특성**과 **분포**가 다르므로 개별적인 시계열 모델링이 필요해 보입나다.


```python
##store의 시계열 plot과 distplot
store_plot(resampling_data,0,10)
store_displot(resampling_data,0,5)
```


    
![png](1st_code_files/1st_code_32_0.png)
    



    
![png](1st_code_files/1st_code_32_1.png)
    


귀무가설(H0): 자료에 **단위근**이 존재한다.<br>
대립가설(H1): 시계열 자료가 **정상성**을 만족한다(또는 추세 정상성을 만족한다)<br>
대부분 상점들의 **p-value**값이 **0.05**보다 높으므로 **귀무가설**이 채택되고 시계열 자료의 **정상성**을 만족하기 시키기 위해 **차분**이 필요해 보입니다.




```python
##전체 상점 adf_test p-value값을 계산하여 boxplot
adf_p=[]
for i in tqdm(resampling_data['store_id'].unique()):
    ts=time_series(resampling_data,i)
    adf_p.append(adf_test(ts))
    
plt.figure(figsize=(8, 4))    
sns.boxplot(adf_p)
```

    100%|█████████████████████████████████████████████████████████████████████████████| 1967/1967 [00:06<00:00, 325.07it/s]
    




    <matplotlib.axes._subplots.AxesSubplot at 0x1a7f5370b48>




    
![png](1st_code_files/1st_code_34_2.png)
    



```python
##상점별로 acf, pacf 그래프 확인
acf_pacf_plot(data=resampling_data,store_id=1)
```


    
![png](1st_code_files/1st_code_35_0.png)
    


## 4. 변수 선택 및 모델 구축
## Feature Engineering & Initial Modeling

* 시계열 모델로 모델링을 진행 하기 때문에 연도-월 변수와 매출액 변수만 유지
* 모델링을 할때 coefficient_variation(매출 변동계수)를 고려해서 log 정규화를 진행 

## 5. 모델 학습 및 검증
## Model Tuning & Evaluation


* 매출액 오차를 줄이기 위해 auto_arima, stl_descompostion+ets model, simple ets model을 average ensemble 진행
* auto.arima는 AIC를 최소로하는 p, d, q값을 자동적으로 탐색
* auto.arima 파라미터는 ndiffs(d값 계산)함수와 acf pcaf그래프로 max.p=2로 고정
* 최종예측은 이후 3개월을 예측하여 합산
* 매출액 변동계수가 큰 상점들에 log 정규화를 했을때 오차가 커지는 경향을 확인 (변동성이 커서 잡음제거 목적을 달성하지 못하고 매출액을 과대 예측)
* 모델링을 진행할때 CV(변동계수)값이 0.3(실험결과 오차가 가장적음)이하인 경우 log 정규화를 하기로 결정
* 충분한 시즌이 없는경우 stl descomposition+ets model을 적합하지 못하고 auto.arima와 ets를 앙상블(stl descompostion은 최소 2시즌이상 데이터 필요)


**forecastHybrid**는 앙상블 시계열 모델을 쉽게 구축 할 수 있게 해주는 패지지입니다.<br>
**robjects.r** 함수는 파이썬에서 **R의 기본 함수**와 **패키지**를 쓸수 있게 도와주고 **str**형식으로 정의된 **R function**도 사용이 가능하게  해줍니다. 


```python
##auto_arima,stl_descompostion+ets,simple ets model ensemble
hybridModel="""
    function(testdata){
        library(forecast)
        library(forecastHybrid)
        d_params=ndiffs(testdata)
        hb_mdl<-hybridModel(testdata,models="aes",
                        a.arg=list(max.p=2,d=d_params),weight="equal")
        forecasted_data<-forecast(hb_mdl,h=3) ##이후 3개월(h=3)을 예측
        outdf<-data.frame(forecasted_data$mean)
        colnames(outdf)<-c('amount')
        outdf
    }
"""

#사용할 R 함수
hybridModel=robjects.r(hybridModel)
ts=robjects.r('ts')
c=robjects.r('c')
log=robjects.r('log')
exp=robjects.r('exp')

final_pred=[]
for i in tqdm(resampling_data.store_id.unique()):
    pred=[]
    
    store=resampling_data[resampling_data['store_id']==i]
    start_year=int(min(store['year_month'])[:4]) ##영업 시작 년도
    start_month=int(min(store['year_month'])[5:]) ##영업 시작 월
    
    cv=coefficient_variation(resampling_data,i)
    ##매출액 변동계수가 0.3이하인 경우만 log를 씌움
    if cv<0.3:
        data=ts(log(store['amount']),start=c(start_year,start_month),frequency=12) #R의 ts함수로 time series데이터로 변환
        ##ensemble model
        forecast=hybridModel(data)
        final_pred.append(np.sum(pandas2ri.ri2py(exp(forecast)).values)) #3개월 매출을 합산,final_pred에 추가
    ##매출액 변동계수가 0.3이상인 경우
    else:
        data=ts(store['amount'],start=c(start_year,start_month),frequency=12)
        ##ensemble model
        forecast=hybridModel(data)
        final_pred.append(np.sum(pandas2ri.ri2py(forecast).values)) #3개월 매출을 합산, final_pred에 추가  
```

    100%|██████████████████████████████████████████████████████████████████████████████| 1967/1967 [16:46<00:00,  1.95it/s]
    


```python
submission['amount']=final_pred
submission.to_csv('submission.csv', index=False)
submission
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>store_id</th>
      <th>amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>1996289.71</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>265304.45</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2</td>
      <td>1240680.98</td>
    </tr>
    <tr>
      <td>3</td>
      <td>4</td>
      <td>2695278.94</td>
    </tr>
    <tr>
      <td>4</td>
      <td>5</td>
      <td>824062.03</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>1962</td>
      <td>2132</td>
      <td>2115932.99</td>
    </tr>
    <tr>
      <td>1963</td>
      <td>2133</td>
      <td>631105.24</td>
    </tr>
    <tr>
      <td>1964</td>
      <td>2134</td>
      <td>302129.20</td>
    </tr>
    <tr>
      <td>1965</td>
      <td>2135</td>
      <td>1626442.38</td>
    </tr>
    <tr>
      <td>1966</td>
      <td>2136</td>
      <td>6504046.21</td>
    </tr>
  </tbody>
</table>
<p>1967 rows × 2 columns</p>
</div>


